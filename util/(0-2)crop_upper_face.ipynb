{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca7686f9-8cb7-4293-953b-b68e8e8ae4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install facenet-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98b1f59a-7397-4667-ba5b-81fea7c717da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "from PIL import Image\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83ed9dc2-e816-4c55-ae29-9d7bff928500",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = 'train'\n",
    "ori_path = Path(f'/opt/ml/input/data/{mod}/images_seg_crop')\n",
    "target_path = Path(f'/opt/ml/input/data/{mod}/images_seg_crop_upper_face')\n",
    "\n",
    "if not os.path.isdir(target_path):\n",
    "    os.mkdir(target_path)\n",
    "\n",
    "csv_path = '/opt/ml/input/data/train/new_train.csv'\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c561117a-4589-473d-9636-002de76c27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n"
     ]
    }
   ],
   "source": [
    "transform = A.Compose([A.Crop(0, 0, 224, 112), A.Resize(224, 224)])\n",
    "\n",
    "for idx in range(len(df)):\n",
    "    path = Path(df.iloc[idx]['path'].replace('images', 'images_seg_crop'))\n",
    "    target_dir = Path(df.iloc[idx]['path'].replace('images', 'images_seg_crop_upper_face')).parent\n",
    "    img = Image.open(path)\n",
    "    if not os.path.isdir(target_dir):\n",
    "        os.mkdir(target_dir)\n",
    "\n",
    "    tar_img_path = target_dir / path.name\n",
    "    trans = Image.fromarray(transform(image=np.array(img))['image'])\n",
    "    trans.save(tar_img_path)\n",
    "    if(idx % 1000 == 0):\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5af55414-d343-41a1-a3c9-e4b7b06da8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            ImageID  ans\n",
      "0      cbc5c6e168e63498590db46022617123f1fe1268.jpg    0\n",
      "1      0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    0\n",
      "2      b549040c49190cedc41327748aeb197c1670f14d.jpg    0\n",
      "3      4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg    0\n",
      "4      248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg    0\n",
      "...                                             ...  ...\n",
      "12595  d71d4570505d6af8f777690e63edfa8d85ea4476.jpg    0\n",
      "12596  6cf1300e8e218716728d5820c0bab553306c2cfd.jpg    0\n",
      "12597  8140edbba31c3a824e817e6d5fb95343199e2387.jpg    0\n",
      "12598  030d439efe6fb5a7bafda45a393fc19f2bf57f54.jpg    0\n",
      "12599  f1e0b9594ae9f72571f0a9dc67406ad41f2edab0.jpg    0\n",
      "\n",
      "[12600 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# mod = 'eval'\n",
    "# ori_path = Path(f'/opt/ml/input/data/{mod}/images_seg_crop')\n",
    "# target_path = Path(f'/opt/ml/input/data/{mod}/images_seg_crop_devide')\n",
    "\n",
    "# if not os.path.isdir(target_path):\n",
    "#     os.mkdir(target_path)\n",
    "\n",
    "# csv_path = '/opt/ml/input/data/eval/info.csv'\n",
    "# df = pd.read_csv(csv_path)\n",
    "# print(df)\n",
    "# # img = Image.open(new_path)\n",
    "# # print(np.array(img).shape)\n",
    "# # plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ca72441-6351-4910-836e-33e6c160cc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def faceCrop(img, faces, w_ratio, h_ratio, x, y):\n",
    "#     x1, y1, x2, y2 = faces[0][0]\n",
    "#     width = x2 - x1\n",
    "#     height = y2 - y1\n",
    "    \n",
    "#     new_x = int(x1 - width * w_ratio / 2)\n",
    "#     new_y = int(y1 - height * h_ratio / 2)\n",
    "    \n",
    "#     if(new_x < 0):\n",
    "#         w_ratio = x1 / width\n",
    "#         new_x = 0\n",
    "#     if(new_y < 0):\n",
    "#         h_ratio = y1 / height\n",
    "#         new_y = 0\n",
    "    \n",
    "#     new_width = int(width * (1 + w_ratio))\n",
    "#     new_height = int(height * (1 + h_ratio))\n",
    "    \n",
    "#     if(new_x + new_width > x):\n",
    "#         new_width = x - new_x\n",
    "#     if(new_y + new_height > y):\n",
    "#         new_height = y - new_y \n",
    "        \n",
    "#     transform = A.Compose([\n",
    "#                         A.Crop(new_x, new_y, new_x+new_width, new_y+new_height),\n",
    "#                         A.Resize(224, 224)\n",
    "#                         ])\n",
    "    \n",
    "\n",
    "\n",
    "#     img = transform(image=np.array(img))['image']\n",
    "#     return img\n",
    "# detector = MTCNN()\n",
    "# face = detector.detect(img)\n",
    "# plt.imshow(faceCrop(img, face, 0.3, 0.4, 384, 512))\n",
    "# plt.imshow(faceCrop(img, face, 0.3, 0.4, 224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd029e7e-27d0-412e-98ee-0d83f1dd35f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# li = df[\"mask\"].to_list()\n",
    "# normal_idx = []\n",
    "# for i in range(len(li)):\n",
    "#     if li[i] == 2:\n",
    "#         normal_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "148009ae-cb46-4afd-9e60-5e2370b63ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "# people_n = int(len(df)/7)\n",
    " \n",
    "#     ori_normal_path = Path(df['path'].iloc[normal_idx[idx]].replace('images', 'images_resize'))\n",
    "#     ori_normal_img = Image.open(ori_normal_path)\n",
    "#     ori_normal_face = detector.detect(ori_normal_img)\n",
    "#     for j in range(7):\n",
    "\n",
    "transform = A.Compose([A.Crop(0, 0, 224, 112), A.Resize(224, 224)])\n",
    "for idx in range(len(df)):\n",
    "    ori_img_path = ori_path / Path(df['ImageID'].iloc[idx])\n",
    "    tar_img_path = target_path / Path(df['ImageID'].iloc[idx])\n",
    "\n",
    "    ori_img = Image.open(ori_img_path)\n",
    "    trans = Image.fromarray(transform(image=np.array(ori_img))['image'])\n",
    "#     if not os.path.isdir(tar_path.parent):\n",
    "#         os.mkdir(tar_path.parent)\n",
    "    \n",
    "    trans.save(tar_img_path)\n",
    "    \n",
    "#     seg_img = Image.open(seg_path)\n",
    "    \n",
    "#     ori_face = detector.detect(ori_img)\n",
    "    \n",
    "#     if(ori_face[1][0] != None):\n",
    "#         face_crop_img = Image.fromarray(faceCrop(ori_img, ori_face, 0.3, 0.4, 224, 224))\n",
    "#         seg_crop_img = Image.fromarray(faceCrop(seg_img, ori_face, 0.3, 0.4, 224, 224))\n",
    "#     else:\n",
    "#         face_crop_img = Image.fromarray(transform(image=np.array(ori_img))['image'])\n",
    "#         seg_crop_img = Image.fromarray(transform(image=np.array(seg_img))['image'])\n",
    "#         no_face.append(ori_path)\n",
    "\n",
    "\n",
    "#     face_crop_path = face_crop_dir / Path(df['ImageID'].iloc[idx])\n",
    "#     seg_crop_path = seg_crop_dir / Path(df['ImageID'].iloc[idx])\n",
    "\n",
    "#     face_crop_img.save(face_crop_path)\n",
    "#     seg_crop_img.save(seg_crop_path)\n",
    "\n",
    "    if(idx % 1000 == 0):\n",
    "        print(idx)\n",
    "\n",
    "# print(f'no faces -> {len(no_face)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab338a1a-6836-4a1f-95b0-98245fe94511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
