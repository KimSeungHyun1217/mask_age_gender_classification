{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d949f11c-bb74-4cb7-83a8-19583cd241c9",
   "metadata": {},
   "source": [
    "# 마스크 착용 여부 이미지 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb88d8-6ee7-4958-b8ae-db6d5edcf085",
   "metadata": {},
   "source": [
    "이미지를 시각화하는게 필요해서 노트북으로 옮긴다. (220224 10:49)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce985bf-6593-46bb-9548-9ecefe5f03a3",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c99c502e-5ccd-4c43-ab28-d3047cf50edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import albumentations\n",
    "import albumentations.pytorch.transforms as A\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16088170-904f-46f4-8344-7913d54e238c",
   "metadata": {},
   "source": [
    "## Seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54b9f74d-5fc0-49ef-989a-abfa1bcb1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_set(SEED):\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1844d386-9c24-4aa8-9d5f-fe435677c51b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33e06bd1-cca8-4bbb-88ce-e5da6b4f0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_path, kind=None, transform=None, train=True):\n",
    "        self.kind = kind # mask, gender, age\n",
    "        self.csv_path = csv_path\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        if self.train:\n",
    "            img = Image.open(row['path'])\n",
    "            label = row[self.kind]\n",
    "            if self.transform:\n",
    "                img = self.transform(image=np.array(img))['image']\n",
    "        else:\n",
    "            img = Image.open(row['ImageID'])\n",
    "            label = row['ans']\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9bab119e-e46b-42b2-a68c-1d40ec66635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trainsforms():\n",
    "    transforms = {\n",
    "        'train': albumentations.Compose([A.ToTensorV2()]),\n",
    "        'val': albumentations.Compose([A.ToTensorV2()])\n",
    "    }\n",
    "    return transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229762e-c6ba-4e9a-8278-780f47a3d1c7",
   "metadata": {},
   "source": [
    "## Split train, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "78f1bd61-e97b-4de5-b7ee-9c76a25acd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid(dataset, test_size=0.2, seed=0):\n",
    "    y_train = [y for _, y in train_mask_data_set]\n",
    "    counter_train = collections.Counter(y_train)\n",
    "    print('original y label count', counter_mask_train)\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n",
    "    indices = list(range(len(y_train_mask)))\n",
    "    train_index, val_index = next(iter(sss.split(indices, y_train_mask)))\n",
    "    \n",
    "    train_ds = Subset(dataset, train_index)\n",
    "    val_ds = Subset(dataset, val_index)\n",
    "    y_train = [y for _, y in train_ds]\n",
    "    y_val = [y for _, y in val_ds]\n",
    "    counter_train = collections.Counter(y_train)\n",
    "    counter_val = collections.Counter(y_val)\n",
    "    print(counter_train)\n",
    "    print(counter_val)\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dd4c5d-b240-478a-ba99-6347ff5a301f",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fdec00b9-d6ef-45b2-95ad-c3c739383b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNewNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super(CustomNewNet, self).__init__()\n",
    "        self.resnet34 = models.resnet34(pretrained=True)\n",
    "        num_ftrs = self.resnet34.fc.in_features\n",
    "        self.resnet34.fc = nn.Linear(num_ftrs, n_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet34(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746981d-8aef-4d22-8bd4-faca5e9d1dab",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e05ce53c-3734-47b4-bc22-6353a1a13515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_or_eval(model, data_loaders, criterion, optimizer, scheduler, n_epoch=10, device='cpu'):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for epoch in range(1, n_epoch + 1):\n",
    "        print('Epoch {}/{}'.format(epoch, n_epoch))\n",
    "        print('-' * 30)\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            total = 0\n",
    "            \n",
    "            for imgs, labels in data_loaders[phase]:\n",
    "                imgs = imgs.float().to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(imgs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase ==\"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if(phase == 'train'):\n",
    "                    scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loaders)\n",
    "            epoch_acc = running_corrects.double() / total\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "            \n",
    "    \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "91ded7a7-7e3c-4801-bb5e-2c1da1ff103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_set(SEED)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCH = 5\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-3\n",
    "SEED = 3086\n",
    "\n",
    "model_ft = CustomNewNet(3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f48113c9-2daa-47bc-9964-d5e372c5478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original y label count Counter({0: 13500, 1: 2700, 2: 2700})\n",
      "Counter({0: 10800, 1: 2160, 2: 2160})\n",
      "Counter({0: 2700, 1: 540, 2: 540})\n"
     ]
    }
   ],
   "source": [
    "train_csv_path = '../input/data/train/full_path_three_label.csv'\n",
    "train_mask_ds = MaskedFaceDataset(csv_path=train_csv_path, kind='mask', \n",
    "                                        transform=train_transform, train=True)\n",
    "train_ds, val_ds = split_train_valid(train_mask_ds, 0.2, SEED)\n",
    "data_loaders = {\n",
    "    'train': DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4),\n",
    "    'val': DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b6e527b7-995e-409f-9d76-8440013cacb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "------------------------------\n",
      "train Loss: 84.6439 Acc: 0.9483\n",
      "val Loss: 15.6386 Acc: 0.9706\n",
      "\n",
      "Epoch 2/5\n",
      "------------------------------\n",
      "train Loss: 85.0992 Acc: 0.9495\n",
      "val Loss: 16.5106 Acc: 0.9656\n",
      "\n",
      "Epoch 3/5\n",
      "------------------------------\n",
      "train Loss: 84.5187 Acc: 0.9481\n",
      "val Loss: 15.5566 Acc: 0.9685\n",
      "\n",
      "Epoch 4/5\n",
      "------------------------------\n",
      "train Loss: 86.3918 Acc: 0.9478\n",
      "val Loss: 16.0216 Acc: 0.9690\n",
      "\n",
      "Epoch 5/5\n",
      "------------------------------\n",
      "train Loss: 83.9424 Acc: 0.9477\n",
      "val Loss: 16.1025 Acc: 0.9690\n",
      "\n",
      "Training complete in 10m 35s\n"
     ]
    }
   ],
   "source": [
    "model_result = train_or_eval(model_ft, data_loaders, criterion, optimizer, scheduler, EPOCH, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c6c5cae2-9a76-4e7f-a1ed-cddd8b729023",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '../model'\n",
    "torch.save({'epoch': EPOCH,\n",
    "            'model_state_dict': model_result.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "           }, os.path.join(save_path, \"resnet34_mask_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "071f5735-f0a3-4870-98bc-31e129fb6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(save_path, \"resnet34_mask_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878a6c3d-fe6f-401c-84f3-cf22311c619e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117a6b6-29ff-407b-be76-fe018c2c4745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
