{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d949f11c-bb74-4cb7-83a8-19583cd241c9",
   "metadata": {},
   "source": [
    "# 마스크 착용 여부 이미지 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eb88d8-6ee7-4958-b8ae-db6d5edcf085",
   "metadata": {},
   "source": [
    "이미지를 시각화하는게 필요해서 노트북으로 옮긴다. (220224 10:49)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce985bf-6593-46bb-9548-9ecefe5f03a3",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c99c502e-5ccd-4c43-ab28-d3047cf50edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import albumentations\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "509faa5b-052f-4f9e-8264-4be4ba8471a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16088170-904f-46f4-8344-7913d54e238c",
   "metadata": {},
   "source": [
    "## Seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "54b9f74d-5fc0-49ef-989a-abfa1bcb1f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3086\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)  # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1844d386-9c24-4aa8-9d5f-fe435677c51b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33e06bd1-cca8-4bbb-88ce-e5da6b4f0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedFaceDataset(Dataset):\n",
    "    def __init__(self, csv_path, kind=None, transform=None, train=True):\n",
    "        self.kind = kind # mask, gender, age\n",
    "        self.csv_path = csv_path\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "        self.df = pd.read_csv(self.csv_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        if self.train:\n",
    "            img = Image.open(row['path'])\n",
    "            label = row[self.kind]\n",
    "            if self.transform:\n",
    "                img = self.transform(image=np.array(img))['image']\n",
    "        else:\n",
    "            img = Image.open(row['ImageID'])\n",
    "            label = row['ans']\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c70afa86-791b-4098-95c7-0298db3a8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = albumentations.Compose([ToTensorV2()]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9e887376-1cf6-4722-81e8-3a01440ae110",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = '../input/data/train/full_path_three_label.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2332a427-f174-47bf-8f61-b4e8f9b62fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_data_set = MaskedFaceDataset(csv_path=train_csv_path, kind='mask', \n",
    "                                        transform=train_transform, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4229762e-c6ba-4e9a-8278-780f47a3d1c7",
   "metadata": {},
   "source": [
    "## train, validation 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d8e6e925-7af5-4ba3-a64c-81335fef5644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 13500, 1: 2700, 2: 2700})\n"
     ]
    }
   ],
   "source": [
    "y_train_mask = [y for _, y in train_mask_data_set]\n",
    "counter_mask_train = collections.Counter(y_train_mask)\n",
    "print(counter_mask_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a0a2581f-ed6f-4015-bdfb-309e63879666",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1db675cf-78a8-4750-972e-846e65a91c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [11632 10335 12271 ...   607   462  3491] val: [18425  6054 16566 ...  1993 12262 18655]\n",
      "15120 3780\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(y_train_mask)))\n",
    "for train_index, val_index in sss.split(indices, y_train_mask):\n",
    "    print('train:', train_index, 'val:', val_index)\n",
    "    print(len(train_index), len(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c69f4ec0-aaac-44b8-9f0a-6c244f574d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask_ds = Subset(train_mask_data_set, train_index)\n",
    "val_mask_ds = Subset(train_mask_data_set, val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "51f50637-37b7-4e3e-bf3a-ffd3ed65fde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 10800, 1: 2160, 2: 2160})\n",
      "Counter({0: 2700, 1: 540, 2: 540})\n"
     ]
    }
   ],
   "source": [
    "y_train = [y for _, y in train_mask_ds]\n",
    "y_val = [y for _, y in val_mask_ds]\n",
    "\n",
    "counter_train = collections.Counter(y_train)\n",
    "counter_val = collections.Counter(y_val)\n",
    "print(counter_train)\n",
    "print(counter_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5746981d-8aef-4d22-8bd4-faca5e9d1dab",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "00f35c6e-fffd-470c-ada7-f0b653d17f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 5\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1eefb4f2-f701-431f-9c01-fa75534cb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_mask_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_dl = DataLoader(val_mask_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3811e9c9-45af-45c6-8fae-ec9070e5fd35",
   "metadata": {},
   "source": [
    "모델 불러오기 -> resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3ead473c-1fca-4d3c-aadf-dfbb78e5eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet34 = models.resnet34(pretrained=True)\n",
    "num_ftrs = resnet34.fc.in_features\n",
    "resnet34.fc = nn.Linear(num_ftrs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e05ce53c-3734-47b4-bc22-6353a1a13515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # 모델을 학습 모드로 설정\n",
    "            else:\n",
    "                model.eval()   # 모델을 평가 모드로 설정\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # 데이터를 반복\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # 매개변수 경사도를 0으로 설정\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 순전파\n",
    "                # 학습 시에만 연산 기록을 추적\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # 학습 단계인 경우 역전파 + 최적화\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # 통계\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # 모델을 깊은 복사(deep copy)함\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # 가장 나은 모델 가중치를 불러옴\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ec9b3-1c2f-4656-8e8c-8e491e0279dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
