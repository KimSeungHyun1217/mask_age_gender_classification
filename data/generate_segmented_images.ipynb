{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e94ddc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.segmentation import fcn_resnet50\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61418a41",
   "metadata": {},
   "source": [
    "> ## 사용법\n",
    "\n",
    "1. `./data`로 current working directory 변경\n",
    "2. train 데이터 바꾸고 싶으면 `train_dir = True`, eval 데이터 바꾸고 싶으면 `train_dir = False`\n",
    "2. 코드 실행\n",
    "3. `./data/train/images_segmented/...`에 segmented 이미지들 원래랑 똑같은 구조로 저장됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9039463",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = True\n",
    "target_dir = 'train' if train_dir else 'eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6920316",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_img_dir_path = './{}/images_segmented'.format(target_dir)\n",
    "orig_img_dir_path = './{}/images'.format(target_dir)\n",
    "if not os.path.isdir(segmented_img_dir_path):\n",
    "    os.mkdir(segmented_img_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af45d553",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fcn_resnet50(pretrained=True, progress=False)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c49a5f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_img(img):\n",
    "    transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    A.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    original_img = img\n",
    "\n",
    "    img = transform(image=np.array(img))['image']\n",
    "    img_batch = img.unsqueeze(0)\n",
    "\n",
    "    output = model(img_batch)['out']\n",
    "    normalized_masks = torch.nn.functional.softmax(output, dim=1)\n",
    "\n",
    "    person_mask = normalized_masks[0,15]\n",
    "    masked_img = person_mask.detach().numpy()\n",
    "    \n",
    "    boundary = 5\n",
    "    xmax = masked_img.shape[0]\n",
    "    ymax = masked_img.shape[1]\n",
    "    \n",
    "    masked_img = masked_img > 0.9\n",
    "    temp_masked_img = masked_img.copy()\n",
    "\n",
    "    for i in range(ymax):\n",
    "        for j in range(xmax):\n",
    "            if temp_masked_img[i,j] == True:\n",
    "                x_left, x_right = max(0,j-boundary), min(xmax-1, j+boundary)\n",
    "                y_down, y_up = max(0,i-boundary), min(ymax-1, i+boundary)\n",
    "                masked_img[y_down:y_up, x_left:x_right] = 1\n",
    "\n",
    "    original_img = A.Resize(224,224)(image=np.array(original_img))['image']\n",
    "    masked_img = np.expand_dims(masked_img, axis = 2)\n",
    "    masked_img = np.concatenate((masked_img, masked_img, masked_img), axis=2)\n",
    "    \n",
    "    return original_img * masked_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d0faa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "def train_segment():\n",
    "    for person_dir in os.listdir(orig_img_dir_path):\n",
    "        for fname in os.listdir(Path(orig_img_dir_path) / person_dir):\n",
    "            img_full_path = Path(orig_img_dir_path) / person_dir / fname\n",
    "            img = Image.open(img_full_path)\n",
    "            segmented_img = Image.fromarray(segment_img(img))\n",
    "\n",
    "            new_dir = Path(segmented_img_dir_path) / person_dir\n",
    "            if not os.path.isdir(new_dir):\n",
    "                os.makedirs(new_dir)\n",
    "            new_path = new_dir / fname\n",
    "            segmented_img.save(new_path)\n",
    "        global cnt\n",
    "        cnt += 1\n",
    "        if cnt > 5:\n",
    "            break\n",
    "\n",
    "def eval_segment():\n",
    "    for fname in os.listdir(Path(orig_img_dir_path)):\n",
    "        img_full_path = Path(orig_img_dir_path) / fname\n",
    "        img = Image.open(img_full_path)\n",
    "        segmented_img = Image.fromarray(segment_img(img))\n",
    "        \n",
    "        new_dir = Path(segmented_img_dir_path)\n",
    "        if not os.path.isdir(new_dir):\n",
    "            os.makedirs(new_dir)\n",
    "        \n",
    "        new_path = new_dir / fname\n",
    "        segmented_img.save(new_path)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8904733",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_dir:\n",
    "    train_segment()\n",
    "else:\n",
    "    eval_segment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "603f6688",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'eval/images_segmented/003106_female_Asian_20'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-604-c4a232733f08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mseg_fname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_person_seg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_person_seg_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mseg_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eval/images_segmented/003106_female_Asian_20'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3600x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test_person_seg_dir = Path(segmented_img_dir_path) / '003106_female_Asian_20'\n",
    "# test_person_orig_dir = Path(orig_img_dir_path) / '003106_female_Asian_20'\n",
    "\n",
    "# cnt = 1\n",
    "# plt.figure(figsize=(50,20))\n",
    "\n",
    "# for seg_fname in os.listdir(test_person_seg_dir):\n",
    "#     img = Image.open(test_person_seg_dir / seg_fname)\n",
    "#     plt.subplot(2,7,cnt)\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     cnt += 1\n",
    "    \n",
    "# for seg_fname in os.listdir(test_person_orig_dir):\n",
    "#     img = Image.open(test_person_orig_dir / seg_fname)\n",
    "#     plt.subplot(2,7,cnt)\n",
    "#     plt.imshow(img)\n",
    "#     plt.axis('off')\n",
    "#     cnt += 1\n",
    "    \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e235405f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960f669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
